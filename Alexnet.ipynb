{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms, datasets, utils\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummaryX import summary\n",
    "from model import AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, init_weights=False):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                 \n",
    "            nn.Conv2d(48, 128, kernel_size=5, padding=2),          \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),                \n",
    "            nn.Conv2d(128, 192, kernel_size=3, padding=1),        \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, kernel_size=3, padding=1),       \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 128, kernel_size=3, padding=1),       \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),               \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128 * 6 * 6, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "        \"val\": transforms.Compose([transforms.Resize((224, 224)),  \n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\n",
    "    data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "    image_path = os.path.join(data_root, \"data_set\", \"flower_data\")  # flower data set path\n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "    train_num = len(train_dataset)\n",
    "\n",
    "    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
    "    flower_list = train_dataset.class_to_idx\n",
    "    cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    batch_size = 32\n",
    "    nw =0\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                            transform=data_transform[\"val\"])\n",
    "    val_num = len(validate_dataset)\n",
    "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=4, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "\n",
    "\n",
    "    net = AlexNet(num_classes=2, init_weights=True)\n",
    "    xx=torch.zeros(1,3,224,224)\n",
    "    summary(net,xx)\n",
    "    net.to(device)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
    "\n",
    "    epochs = 30\n",
    "    save_path = './AlexNet.pth'\n",
    "    best_acc = 0.0\n",
    "    train_steps = len(train_loader)\n",
    "    timlist=[]\n",
    "    t_loss=[]\n",
    "    val_a=[]\n",
    "    nowtim=time.perf_counter()\n",
    "    timlist.append(nowtim)\n",
    "    val_a.append(0)\n",
    "    t_loss.append(1)\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images.to(device))\n",
    "            loss = loss_function(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        tim=time.perf_counter()\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f time:%.3lf' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate,tim-nowtim))\n",
    "        nowtim=tim\n",
    "        timlist.append(nowtim)\n",
    "        val_a.append(val_accurate)\n",
    "        t_loss.append(running_loss / train_steps)\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "    print('Finished Training')\n",
    "    return timlist,val_a,t_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data_transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # load image\n",
    "    #img_path = \"../tulip.jpg\"\n",
    "    #assert os.path.exists(img_path), \"file: '{}' dose not exist.\".format(img_path)\n",
    "    #img = Image.open(img_path)\n",
    "    \n",
    "    \n",
    "    path_img = './testimages/'\n",
    "    ls = os.listdir(path_img)\n",
    "    pre=[]\n",
    "    for i in ls:\n",
    "        img = Image.open(f\"./testimages/{i}\")\n",
    "\n",
    "        #plt.imshow(img)\n",
    "        # [N, C, H, W]\n",
    "        img = data_transform(img)\n",
    "        # expand batch dimension\n",
    "        img = torch.unsqueeze(img, dim=0)\n",
    "\n",
    "        # read class_indict\n",
    "        json_path = './class_indices.json'\n",
    "        assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            class_indict = json.load(f)\n",
    "\n",
    "        # create model\n",
    "        model = AlexNet(num_classes=2).to(device)\n",
    "\n",
    "        # load model weights\n",
    "        weights_path = \"./AlexNet.pth\"\n",
    "        assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # predict class\n",
    "            output = torch.squeeze(model(img.to(device))).cpu()\n",
    "            predict = torch.softmax(output, dim=0)\n",
    "            predict_cla = torch.argmax(predict).numpy()\n",
    "\n",
    "        print_res = \"class: {}   prob: {:.3}\".format(class_indict[str(predict_cla)],\n",
    "                                                     predict[predict_cla].numpy())\n",
    "        if class_indict[str(predict_cla)]=='male':\n",
    "            pre.append(1)\n",
    "        else:\n",
    "            pre.append(-1)\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device.\n",
      "Using 0 dataloader workers every process\n",
      "using 2701 images for training, 299 images for validation.\n",
      "====================================================================================\n",
      "                              Kernel Shape      Output Shape     Params  \\\n",
      "Layer                                                                     \n",
      "0_features.Conv2d_0        [3, 48, 11, 11]   [1, 48, 55, 55]    17.472k   \n",
      "1_features.ReLU_1                        -   [1, 48, 55, 55]          -   \n",
      "2_features.MaxPool2d_2                   -   [1, 48, 27, 27]          -   \n",
      "3_features.Conv2d_3        [48, 128, 5, 5]  [1, 128, 27, 27]   153.728k   \n",
      "4_features.ReLU_4                        -  [1, 128, 27, 27]          -   \n",
      "5_features.MaxPool2d_5                   -  [1, 128, 13, 13]          -   \n",
      "6_features.Conv2d_6       [128, 192, 3, 3]  [1, 192, 13, 13]   221.376k   \n",
      "7_features.ReLU_7                        -  [1, 192, 13, 13]          -   \n",
      "8_features.Conv2d_8       [192, 192, 3, 3]  [1, 192, 13, 13]   331.968k   \n",
      "9_features.ReLU_9                        -  [1, 192, 13, 13]          -   \n",
      "10_features.Conv2d_10     [192, 128, 3, 3]  [1, 128, 13, 13]   221.312k   \n",
      "11_features.ReLU_11                      -  [1, 128, 13, 13]          -   \n",
      "12_features.MaxPool2d_12                 -    [1, 128, 6, 6]          -   \n",
      "13_classifier.Dropout_0                  -         [1, 4608]          -   \n",
      "14_classifier.Linear_1        [4608, 2048]         [1, 2048]  9.439232M   \n",
      "15_classifier.ReLU_2                     -         [1, 2048]          -   \n",
      "16_classifier.Dropout_3                  -         [1, 2048]          -   \n",
      "17_classifier.Linear_4        [2048, 2048]         [1, 2048]  4.196352M   \n",
      "18_classifier.ReLU_5                     -         [1, 2048]          -   \n",
      "19_classifier.Linear_6           [2048, 2]            [1, 2]     4.098k   \n",
      "\n",
      "                           Mult-Adds  \n",
      "Layer                                 \n",
      "0_features.Conv2d_0         52.7076M  \n",
      "1_features.ReLU_1                  -  \n",
      "2_features.MaxPool2d_2             -  \n",
      "3_features.Conv2d_3        111.9744M  \n",
      "4_features.ReLU_4                  -  \n",
      "5_features.MaxPool2d_5             -  \n",
      "6_features.Conv2d_6       37.380096M  \n",
      "7_features.ReLU_7                  -  \n",
      "8_features.Conv2d_8       56.070144M  \n",
      "9_features.ReLU_9                  -  \n",
      "10_features.Conv2d_10     37.380096M  \n",
      "11_features.ReLU_11                -  \n",
      "12_features.MaxPool2d_12           -  \n",
      "13_classifier.Dropout_0            -  \n",
      "14_classifier.Linear_1     9.437184M  \n",
      "15_classifier.ReLU_2               -  \n",
      "16_classifier.Dropout_3            -  \n",
      "17_classifier.Linear_4     4.194304M  \n",
      "18_classifier.ReLU_5               -  \n",
      "19_classifier.Linear_6        4.096k  \n",
      "------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          14.585538M\n",
      "Trainable params      14.585538M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             309.14792M\n",
      "====================================================================================\n",
      "train epoch[1/2] loss:0.036:  65%|██████████████████████████████████▎                  | 55/85 [00:27<00:15,  1.96it/s]"
     ]
    }
   ],
   "source": [
    "a,b,c=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "a.extend(b)\n",
    "a.extend(c)\n",
    "a=np.array(a)\n",
    "a=np.resize(a,(3,3))\n",
    "print(a)\n",
    "df = pd.DataFrame(a)\n",
    "df.to_csv('Alexnetdata.csv',index= False, header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = './testimages/'\n",
    "ls = os.listdir(path_img)\n",
    "name=[]\n",
    "for i in ls:\n",
    "    name.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out_dict = {\n",
    "    'image_id':list(name),\n",
    "    'is_male':list(pre)\n",
    "}\n",
    "out = pd.DataFrame(out_dict)\n",
    "out.to_csv('Alexnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
