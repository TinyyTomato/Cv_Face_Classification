{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms, datasets, utils\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 blocks_num,\n",
    "                 num_classes=1000,\n",
    "                 include_top=True,\n",
    "                 groups=1,\n",
    "                 width_per_group=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64\n",
    "\n",
    "        self.groups = groups\n",
    "        self.width_per_group = width_per_group\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel,\n",
    "                            channel,\n",
    "                            downsample=downsample,\n",
    "                            stride=stride,\n",
    "                            groups=self.groups,\n",
    "                            width_per_group=self.width_per_group))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel,\n",
    "                                channel,\n",
    "                                groups=self.groups,\n",
    "                                width_per_group=self.width_per_group))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet34(num_classes=1000, include_top=True):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "        \"val\": transforms.Compose([transforms.Resize((224, 224)),  \n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\n",
    "\n",
    "    data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "    image_path = os.path.join(data_root, \"data_set\", \"face_data\")  \n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "    train_num = len(train_dataset)\n",
    "\n",
    "\n",
    "    face_list = train_dataset.class_to_idx\n",
    "    cla_dict = dict((val, key) for key, val in face_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    batch_size = 16\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    nw =0 \n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                            transform=data_transform[\"val\"])\n",
    "    val_num = len(validate_dataset)\n",
    "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "    \n",
    "    net = resnet34()\n",
    "\n",
    "    model_weight_path = \"./resnet34-pre.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
    "    in_channel = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_channel, 2)\n",
    "    net.to(device)\n",
    "    summary(net,torch.zeros(1,3,224,224))\n",
    "    # define loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params, lr=0.0002)\n",
    "\n",
    "    epochs = 30\n",
    "    best_acc = 0.0\n",
    "    save_path = './resNet34.pth'\n",
    "    train_steps = len(train_loader)\n",
    "    train_steps = len(train_loader)\n",
    "    timlist=[]\n",
    "    t_loss=[]\n",
    "    val_a=[]\n",
    "    nowtim=time.perf_counter()\n",
    "    timlist.append(nowtim)\n",
    "    val_a.append(0)\n",
    "    t_loss.append(1)\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            logits = net(images.to(device))\n",
    "            loss = loss_function(logits, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                loss = loss_function(outputs, test_labels)\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
    "                                                           epochs)\n",
    "        tim=time.perf_counter()\n",
    "        val_accurate = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f time:%.3lf' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate,tim-nowtim))\n",
    "        nowtim=tim\n",
    "        timlist.append(nowtim)\n",
    "        val_a.append(val_accurate)\n",
    "        t_loss.append(running_loss / train_steps)\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "    return timlist,val_a,t_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data_transform = transforms.Compose([transforms.Resize((224, 224)),  \n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # load image\n",
    "    path_img = './testimages/'\n",
    "    ls = os.listdir(path_img)\n",
    "    pre=[]\n",
    "    for i in ls:\n",
    "        img = Image.open(f\"./testimages/{i}\")\n",
    "        # [N, C, H, W]\n",
    "        img = data_transform(img)\n",
    "        # expand batch dimension\n",
    "        img = torch.unsqueeze(img, dim=0)\n",
    "\n",
    "        # read class_indict\n",
    "        json_path = './class_indices.json'\n",
    "        assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            class_indict = json.load(f)\n",
    "\n",
    "        # create model\n",
    "        model = resnet34(num_classes=2).to(device)\n",
    "\n",
    "        # load model weights\n",
    "        weights_path = \"./resNet34.pth\"\n",
    "        assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
    "        model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "\n",
    "        # prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # predict class\n",
    "            output = torch.squeeze(model(img.to(device))).cpu()\n",
    "            predict = torch.softmax(output, dim=0)\n",
    "            predict_cla = torch.argmax(predict).numpy()\n",
    "\n",
    "        print_res = \"class: {}   prob: {:.3}\".format(class_indict[str(predict_cla)],\n",
    "                                                     predict[predict_cla].numpy())\n",
    "        if class_indict[str(predict_cla)]=='male':\n",
    "            pre.append(1)\n",
    "        else:\n",
    "            pre.append(-1)\n",
    "\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device.\n",
      "Using 0 dataloader workers every process\n",
      "using 2701 images for training, 299 images for validation.\n",
      "=================================================================================================\n",
      "                                          Kernel Shape       Output Shape  \\\n",
      "Layer                                                                       \n",
      "0_conv1                                  [3, 64, 7, 7]  [1, 64, 112, 112]   \n",
      "1_bn1                                             [64]  [1, 64, 112, 112]   \n",
      "2_relu                                               -  [1, 64, 112, 112]   \n",
      "3_maxpool                                            -    [1, 64, 56, 56]   \n",
      "4_layer1.0.Conv2d_conv1                 [64, 64, 3, 3]    [1, 64, 56, 56]   \n",
      "5_layer1.0.BatchNorm2d_bn1                        [64]    [1, 64, 56, 56]   \n",
      "6_layer1.0.ReLU_relu                                 -    [1, 64, 56, 56]   \n",
      "7_layer1.0.Conv2d_conv2                 [64, 64, 3, 3]    [1, 64, 56, 56]   \n",
      "8_layer1.0.BatchNorm2d_bn2                        [64]    [1, 64, 56, 56]   \n",
      "9_layer1.0.ReLU_relu                                 -    [1, 64, 56, 56]   \n",
      "10_layer1.1.Conv2d_conv1                [64, 64, 3, 3]    [1, 64, 56, 56]   \n",
      "11_layer1.1.BatchNorm2d_bn1                       [64]    [1, 64, 56, 56]   \n",
      "12_layer1.1.ReLU_relu                                -    [1, 64, 56, 56]   \n",
      "13_layer1.1.Conv2d_conv2                [64, 64, 3, 3]    [1, 64, 56, 56]   \n",
      "14_layer1.1.BatchNorm2d_bn2                       [64]    [1, 64, 56, 56]   \n",
      "15_layer1.1.ReLU_relu                                -    [1, 64, 56, 56]   \n",
      "16_layer1.2.Conv2d_conv1                [64, 64, 3, 3]    [1, 64, 56, 56]   \n",
      "17_layer1.2.BatchNorm2d_bn1                       [64]    [1, 64, 56, 56]   \n",
      "18_layer1.2.ReLU_relu                                -    [1, 64, 56, 56]   \n",
      "19_layer1.2.Conv2d_conv2                [64, 64, 3, 3]    [1, 64, 56, 56]   \n",
      "20_layer1.2.BatchNorm2d_bn2                       [64]    [1, 64, 56, 56]   \n",
      "21_layer1.2.ReLU_relu                                -    [1, 64, 56, 56]   \n",
      "22_layer2.0.downsample.Conv2d_0        [64, 128, 1, 1]   [1, 128, 28, 28]   \n",
      "23_layer2.0.downsample.BatchNorm2d_1             [128]   [1, 128, 28, 28]   \n",
      "24_layer2.0.Conv2d_conv1               [64, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "25_layer2.0.BatchNorm2d_bn1                      [128]   [1, 128, 28, 28]   \n",
      "26_layer2.0.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "27_layer2.0.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "28_layer2.0.BatchNorm2d_bn2                      [128]   [1, 128, 28, 28]   \n",
      "29_layer2.0.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "30_layer2.1.Conv2d_conv1              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "31_layer2.1.BatchNorm2d_bn1                      [128]   [1, 128, 28, 28]   \n",
      "32_layer2.1.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "33_layer2.1.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "34_layer2.1.BatchNorm2d_bn2                      [128]   [1, 128, 28, 28]   \n",
      "35_layer2.1.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "36_layer2.2.Conv2d_conv1              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "37_layer2.2.BatchNorm2d_bn1                      [128]   [1, 128, 28, 28]   \n",
      "38_layer2.2.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "39_layer2.2.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "40_layer2.2.BatchNorm2d_bn2                      [128]   [1, 128, 28, 28]   \n",
      "41_layer2.2.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "42_layer2.3.Conv2d_conv1              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "43_layer2.3.BatchNorm2d_bn1                      [128]   [1, 128, 28, 28]   \n",
      "44_layer2.3.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "45_layer2.3.Conv2d_conv2              [128, 128, 3, 3]   [1, 128, 28, 28]   \n",
      "46_layer2.3.BatchNorm2d_bn2                      [128]   [1, 128, 28, 28]   \n",
      "47_layer2.3.ReLU_relu                                -   [1, 128, 28, 28]   \n",
      "48_layer3.0.downsample.Conv2d_0       [128, 256, 1, 1]   [1, 256, 14, 14]   \n",
      "49_layer3.0.downsample.BatchNorm2d_1             [256]   [1, 256, 14, 14]   \n",
      "50_layer3.0.Conv2d_conv1              [128, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "51_layer3.0.BatchNorm2d_bn1                      [256]   [1, 256, 14, 14]   \n",
      "52_layer3.0.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "53_layer3.0.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "54_layer3.0.BatchNorm2d_bn2                      [256]   [1, 256, 14, 14]   \n",
      "55_layer3.0.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "56_layer3.1.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "57_layer3.1.BatchNorm2d_bn1                      [256]   [1, 256, 14, 14]   \n",
      "58_layer3.1.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "59_layer3.1.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "60_layer3.1.BatchNorm2d_bn2                      [256]   [1, 256, 14, 14]   \n",
      "61_layer3.1.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "62_layer3.2.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "63_layer3.2.BatchNorm2d_bn1                      [256]   [1, 256, 14, 14]   \n",
      "64_layer3.2.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "65_layer3.2.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "66_layer3.2.BatchNorm2d_bn2                      [256]   [1, 256, 14, 14]   \n",
      "67_layer3.2.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "68_layer3.3.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "69_layer3.3.BatchNorm2d_bn1                      [256]   [1, 256, 14, 14]   \n",
      "70_layer3.3.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "71_layer3.3.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "72_layer3.3.BatchNorm2d_bn2                      [256]   [1, 256, 14, 14]   \n",
      "73_layer3.3.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "74_layer3.4.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "75_layer3.4.BatchNorm2d_bn1                      [256]   [1, 256, 14, 14]   \n",
      "76_layer3.4.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "77_layer3.4.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "78_layer3.4.BatchNorm2d_bn2                      [256]   [1, 256, 14, 14]   \n",
      "79_layer3.4.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "80_layer3.5.Conv2d_conv1              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "81_layer3.5.BatchNorm2d_bn1                      [256]   [1, 256, 14, 14]   \n",
      "82_layer3.5.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "83_layer3.5.Conv2d_conv2              [256, 256, 3, 3]   [1, 256, 14, 14]   \n",
      "84_layer3.5.BatchNorm2d_bn2                      [256]   [1, 256, 14, 14]   \n",
      "85_layer3.5.ReLU_relu                                -   [1, 256, 14, 14]   \n",
      "86_layer4.0.downsample.Conv2d_0       [256, 512, 1, 1]     [1, 512, 7, 7]   \n",
      "87_layer4.0.downsample.BatchNorm2d_1             [512]     [1, 512, 7, 7]   \n",
      "88_layer4.0.Conv2d_conv1              [256, 512, 3, 3]     [1, 512, 7, 7]   \n",
      "89_layer4.0.BatchNorm2d_bn1                      [512]     [1, 512, 7, 7]   \n",
      "90_layer4.0.ReLU_relu                                -     [1, 512, 7, 7]   \n",
      "91_layer4.0.Conv2d_conv2              [512, 512, 3, 3]     [1, 512, 7, 7]   \n",
      "92_layer4.0.BatchNorm2d_bn2                      [512]     [1, 512, 7, 7]   \n",
      "93_layer4.0.ReLU_relu                                -     [1, 512, 7, 7]   \n",
      "94_layer4.1.Conv2d_conv1              [512, 512, 3, 3]     [1, 512, 7, 7]   \n",
      "95_layer4.1.BatchNorm2d_bn1                      [512]     [1, 512, 7, 7]   \n",
      "96_layer4.1.ReLU_relu                                -     [1, 512, 7, 7]   \n",
      "97_layer4.1.Conv2d_conv2              [512, 512, 3, 3]     [1, 512, 7, 7]   \n",
      "98_layer4.1.BatchNorm2d_bn2                      [512]     [1, 512, 7, 7]   \n",
      "99_layer4.1.ReLU_relu                                -     [1, 512, 7, 7]   \n",
      "100_layer4.2.Conv2d_conv1             [512, 512, 3, 3]     [1, 512, 7, 7]   \n",
      "101_layer4.2.BatchNorm2d_bn1                     [512]     [1, 512, 7, 7]   \n",
      "102_layer4.2.ReLU_relu                               -     [1, 512, 7, 7]   \n",
      "103_layer4.2.Conv2d_conv2             [512, 512, 3, 3]     [1, 512, 7, 7]   \n",
      "104_layer4.2.BatchNorm2d_bn2                     [512]     [1, 512, 7, 7]   \n",
      "105_layer4.2.ReLU_relu                               -     [1, 512, 7, 7]   \n",
      "106_avgpool                                          -     [1, 512, 1, 1]   \n",
      "107_fc                                        [512, 2]             [1, 2]   \n",
      "\n",
      "                                         Params    Mult-Adds  \n",
      "Layer                                                         \n",
      "0_conv1                                  9.408k  118.013952M  \n",
      "1_bn1                                     128.0         64.0  \n",
      "2_relu                                        -            -  \n",
      "3_maxpool                                     -            -  \n",
      "4_layer1.0.Conv2d_conv1                 36.864k  115.605504M  \n",
      "5_layer1.0.BatchNorm2d_bn1                128.0         64.0  \n",
      "6_layer1.0.ReLU_relu                          -            -  \n",
      "7_layer1.0.Conv2d_conv2                 36.864k  115.605504M  \n",
      "8_layer1.0.BatchNorm2d_bn2                128.0         64.0  \n",
      "9_layer1.0.ReLU_relu                          -            -  \n",
      "10_layer1.1.Conv2d_conv1                36.864k  115.605504M  \n",
      "11_layer1.1.BatchNorm2d_bn1               128.0         64.0  \n",
      "12_layer1.1.ReLU_relu                         -            -  \n",
      "13_layer1.1.Conv2d_conv2                36.864k  115.605504M  \n",
      "14_layer1.1.BatchNorm2d_bn2               128.0         64.0  \n",
      "15_layer1.1.ReLU_relu                         -            -  \n",
      "16_layer1.2.Conv2d_conv1                36.864k  115.605504M  \n",
      "17_layer1.2.BatchNorm2d_bn1               128.0         64.0  \n",
      "18_layer1.2.ReLU_relu                         -            -  \n",
      "19_layer1.2.Conv2d_conv2                36.864k  115.605504M  \n",
      "20_layer1.2.BatchNorm2d_bn2               128.0         64.0  \n",
      "21_layer1.2.ReLU_relu                         -            -  \n",
      "22_layer2.0.downsample.Conv2d_0          8.192k    6.422528M  \n",
      "23_layer2.0.downsample.BatchNorm2d_1      256.0        128.0  \n",
      "24_layer2.0.Conv2d_conv1                73.728k   57.802752M  \n",
      "25_layer2.0.BatchNorm2d_bn1               256.0        128.0  \n",
      "26_layer2.0.ReLU_relu                         -            -  \n",
      "27_layer2.0.Conv2d_conv2               147.456k  115.605504M  \n",
      "28_layer2.0.BatchNorm2d_bn2               256.0        128.0  \n",
      "29_layer2.0.ReLU_relu                         -            -  \n",
      "30_layer2.1.Conv2d_conv1               147.456k  115.605504M  \n",
      "31_layer2.1.BatchNorm2d_bn1               256.0        128.0  \n",
      "32_layer2.1.ReLU_relu                         -            -  \n",
      "33_layer2.1.Conv2d_conv2               147.456k  115.605504M  \n",
      "34_layer2.1.BatchNorm2d_bn2               256.0        128.0  \n",
      "35_layer2.1.ReLU_relu                         -            -  \n",
      "36_layer2.2.Conv2d_conv1               147.456k  115.605504M  \n",
      "37_layer2.2.BatchNorm2d_bn1               256.0        128.0  \n",
      "38_layer2.2.ReLU_relu                         -            -  \n",
      "39_layer2.2.Conv2d_conv2               147.456k  115.605504M  \n",
      "40_layer2.2.BatchNorm2d_bn2               256.0        128.0  \n",
      "41_layer2.2.ReLU_relu                         -            -  \n",
      "42_layer2.3.Conv2d_conv1               147.456k  115.605504M  \n",
      "43_layer2.3.BatchNorm2d_bn1               256.0        128.0  \n",
      "44_layer2.3.ReLU_relu                         -            -  \n",
      "45_layer2.3.Conv2d_conv2               147.456k  115.605504M  \n",
      "46_layer2.3.BatchNorm2d_bn2               256.0        128.0  \n",
      "47_layer2.3.ReLU_relu                         -            -  \n",
      "48_layer3.0.downsample.Conv2d_0         32.768k    6.422528M  \n",
      "49_layer3.0.downsample.BatchNorm2d_1      512.0        256.0  \n",
      "50_layer3.0.Conv2d_conv1               294.912k   57.802752M  \n",
      "51_layer3.0.BatchNorm2d_bn1               512.0        256.0  \n",
      "52_layer3.0.ReLU_relu                         -            -  \n",
      "53_layer3.0.Conv2d_conv2               589.824k  115.605504M  \n",
      "54_layer3.0.BatchNorm2d_bn2               512.0        256.0  \n",
      "55_layer3.0.ReLU_relu                         -            -  \n",
      "56_layer3.1.Conv2d_conv1               589.824k  115.605504M  \n",
      "57_layer3.1.BatchNorm2d_bn1               512.0        256.0  \n",
      "58_layer3.1.ReLU_relu                         -            -  \n",
      "59_layer3.1.Conv2d_conv2               589.824k  115.605504M  \n",
      "60_layer3.1.BatchNorm2d_bn2               512.0        256.0  \n",
      "61_layer3.1.ReLU_relu                         -            -  \n",
      "62_layer3.2.Conv2d_conv1               589.824k  115.605504M  \n",
      "63_layer3.2.BatchNorm2d_bn1               512.0        256.0  \n",
      "64_layer3.2.ReLU_relu                         -            -  \n",
      "65_layer3.2.Conv2d_conv2               589.824k  115.605504M  \n",
      "66_layer3.2.BatchNorm2d_bn2               512.0        256.0  \n",
      "67_layer3.2.ReLU_relu                         -            -  \n",
      "68_layer3.3.Conv2d_conv1               589.824k  115.605504M  \n",
      "69_layer3.3.BatchNorm2d_bn1               512.0        256.0  \n",
      "70_layer3.3.ReLU_relu                         -            -  \n",
      "71_layer3.3.Conv2d_conv2               589.824k  115.605504M  \n",
      "72_layer3.3.BatchNorm2d_bn2               512.0        256.0  \n",
      "73_layer3.3.ReLU_relu                         -            -  \n",
      "74_layer3.4.Conv2d_conv1               589.824k  115.605504M  \n",
      "75_layer3.4.BatchNorm2d_bn1               512.0        256.0  \n",
      "76_layer3.4.ReLU_relu                         -            -  \n",
      "77_layer3.4.Conv2d_conv2               589.824k  115.605504M  \n",
      "78_layer3.4.BatchNorm2d_bn2               512.0        256.0  \n",
      "79_layer3.4.ReLU_relu                         -            -  \n",
      "80_layer3.5.Conv2d_conv1               589.824k  115.605504M  \n",
      "81_layer3.5.BatchNorm2d_bn1               512.0        256.0  \n",
      "82_layer3.5.ReLU_relu                         -            -  \n",
      "83_layer3.5.Conv2d_conv2               589.824k  115.605504M  \n",
      "84_layer3.5.BatchNorm2d_bn2               512.0        256.0  \n",
      "85_layer3.5.ReLU_relu                         -            -  \n",
      "86_layer4.0.downsample.Conv2d_0        131.072k    6.422528M  \n",
      "87_layer4.0.downsample.BatchNorm2d_1     1.024k        512.0  \n",
      "88_layer4.0.Conv2d_conv1              1.179648M   57.802752M  \n",
      "89_layer4.0.BatchNorm2d_bn1              1.024k        512.0  \n",
      "90_layer4.0.ReLU_relu                         -            -  \n",
      "91_layer4.0.Conv2d_conv2              2.359296M  115.605504M  \n",
      "92_layer4.0.BatchNorm2d_bn2              1.024k        512.0  \n",
      "93_layer4.0.ReLU_relu                         -            -  \n",
      "94_layer4.1.Conv2d_conv1              2.359296M  115.605504M  \n",
      "95_layer4.1.BatchNorm2d_bn1              1.024k        512.0  \n",
      "96_layer4.1.ReLU_relu                         -            -  \n",
      "97_layer4.1.Conv2d_conv2              2.359296M  115.605504M  \n",
      "98_layer4.1.BatchNorm2d_bn2              1.024k        512.0  \n",
      "99_layer4.1.ReLU_relu                         -            -  \n",
      "100_layer4.2.Conv2d_conv1             2.359296M  115.605504M  \n",
      "101_layer4.2.BatchNorm2d_bn1             1.024k        512.0  \n",
      "102_layer4.2.ReLU_relu                        -            -  \n",
      "103_layer4.2.Conv2d_conv2             2.359296M  115.605504M  \n",
      "104_layer4.2.BatchNorm2d_bn2             1.024k        512.0  \n",
      "105_layer4.2.ReLU_relu                        -            -  \n",
      "106_avgpool                                   -            -  \n",
      "107_fc                                   1.026k       1.024k  \n",
      "-------------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            21.285698M\n",
      "Trainable params        21.285698M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             3.663258944G\n",
      "=================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/30] loss:0.450:   6%|███                                                | 10/169 [00:22<05:56,  2.24s/it]"
     ]
    }
   ],
   "source": [
    "train()\n",
    "pre=test()\n",
    "path_img = './testimages/'\n",
    "ls = os.listdir(path_img)\n",
    "name=[]\n",
    "for i in ls:\n",
    "    name.append(i)\n",
    "import pandas as pd\n",
    "out_dict = {\n",
    "    'image_id':list(name),\n",
    "    'is_male':list(pre)\n",
    "}\n",
    "out = pd.DataFrame(out_dict)\n",
    "out.to_csv('resnet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
