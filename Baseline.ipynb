{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, utils\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchsummaryX import summary\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))    # input(3, 32, 32) output(16, 28, 28)\n",
    "        x = self.pool1(x)            # output(16, 14, 14)\n",
    "        x = F.relu(self.conv2(x))    # output(32, 10, 10)\n",
    "        x = self.pool2(x)            # output(32, 5, 5)\n",
    "        x = x.view(-1, 32*5*5)       # output(32*5*5)\n",
    "        x = F.relu(self.fc1(x))      # output(120)\n",
    "        x = self.fc2(x)              # output(10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose(\n",
    "                            [transforms.Resize((224, 224)),\n",
    "                             transforms.ToTensor()]),\n",
    "        \"val\": transforms.Compose(\n",
    "                        [transforms.Resize((224, 224)),\n",
    "                         transforms.ToTensor()])}\n",
    "    data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "    image_path = os.path.join(data_root, \"data_set\", \"face_data\")  \n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "    train_num = len(train_dataset)\n",
    "\n",
    "\n",
    "    face_list = train_dataset.class_to_idx\n",
    "    cla_dict = dict((val, key) for key, val in face_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    batch_size = 32\n",
    "    nw =0\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                            transform=data_transform[\"val\"])\n",
    "    val_num = len(validate_dataset)\n",
    "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=4, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "\n",
    "\n",
    "    net = BaseNet()\n",
    "    xx=torch.zeros(1,3,224,224)\n",
    "    summary(net,xx)\n",
    "    net.to(device)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
    "\n",
    "    epochs = 30\n",
    "    save_path = './BaseNet.pth'\n",
    "    best_acc = 0.0\n",
    "    train_steps = len(train_loader)\n",
    "    timlist=[]\n",
    "    t_loss=[]\n",
    "    val_a=[]\n",
    "    nowtim=time.perf_counter()\n",
    "    timlist.append(nowtim)\n",
    "    val_a.append(0)\n",
    "    t_loss.append(1)\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images.to(device))\n",
    "            loss = loss_function(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        tim=time.perf_counter()\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f time:%.3lf' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate,tim-nowtim))\n",
    "        nowtim=tim\n",
    "        timlist.append(nowtim)\n",
    "        val_a.append(val_accurate)\n",
    "        t_loss.append(running_loss / train_steps)\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "    print('Finished Training')\n",
    "    return timlist,val_a,t_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    data_transform = transforms.Compose(\n",
    "        [transforms.Resize((224, 224)),\n",
    "         transforms.ToTensor()])\n",
    "\n",
    "    net = BaseNet()\n",
    "    net.load_state_dict(torch.load('BaseNet.pth'))\n",
    "\n",
    "\n",
    "    \n",
    "    json_path = './class_indices.json'\n",
    "    assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        class_indict = json.load(f)\n",
    "    path_img = './testimages/'\n",
    "    ls = os.listdir(path_img)\n",
    "    pre=[]\n",
    "    for i in ls:\n",
    "        img = Image.open(f\"./testimages/{i}\")\n",
    "\n",
    "        #plt.imshow(img)\n",
    "        # [N, C, H, W]\n",
    "        img = data_transform(img)\n",
    "        # expand batch dimension\n",
    "        img = torch.unsqueeze(img, dim=0)\n",
    "        predict=[]\n",
    "        with torch.no_grad():\n",
    "            outputs = net(img)\n",
    "            predict = torch.max(outputs, dim=1)[1].numpy()\n",
    "        if predict[0]==1:\n",
    "            pre.append(1)\n",
    "        else:\n",
    "            pre.append(-1)\n",
    "\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device.\n",
      "Using 0 dataloader workers every process\n",
      "using 2701 images for training, 299 images for validation.\n",
      "============================================================\n",
      "           Kernel Shape     Output Shape   Params Mult-Adds\n",
      "Layer                                                      \n",
      "0_conv1   [3, 16, 5, 5]  [1, 16, 74, 74]   1.216k   6.5712M\n",
      "1_pool1               -  [1, 16, 37, 37]        -         -\n",
      "2_conv2  [16, 32, 5, 5]  [1, 32, 11, 11]  12.832k   1.5488M\n",
      "3_pool2               -    [1, 32, 5, 5]        -         -\n",
      "4_fc1        [800, 120]         [1, 120]   96.12k     96.0k\n",
      "5_fc2          [120, 2]           [1, 2]    242.0     240.0\n",
      "------------------------------------------------------------\n",
      "                        Totals\n",
      "Total params           110.41k\n",
      "Trainable params       110.41k\n",
      "Non-trainable params       0.0\n",
      "Mult-Adds             8.21624M\n",
      "============================================================\n",
      "train epoch[1/30] loss:0.218: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 57.38it/s]\n",
      "[epoch 1] train_loss: 0.442  val_accuracy: 0.936 time:14.489\n",
      "train epoch[2/30] loss:0.103: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 54.29it/s]\n",
      "[epoch 2] train_loss: 0.192  val_accuracy: 0.946 time:14.880\n",
      "train epoch[3/30] loss:0.085: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.43it/s]\n",
      "[epoch 3] train_loss: 0.142  val_accuracy: 0.970 time:14.498\n",
      "train epoch[4/30] loss:0.147: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.79it/s]\n",
      "[epoch 4] train_loss: 0.101  val_accuracy: 0.970 time:14.456\n",
      "train epoch[5/30] loss:0.139: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.16it/s]\n",
      "[epoch 5] train_loss: 0.085  val_accuracy: 0.970 time:14.367\n",
      "train epoch[6/30] loss:0.023: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.33it/s]\n",
      "[epoch 6] train_loss: 0.063  val_accuracy: 0.983 time:14.407\n",
      "train epoch[7/30] loss:0.014: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 55.27it/s]\n",
      "[epoch 7] train_loss: 0.052  val_accuracy: 0.967 time:14.599\n",
      "train epoch[8/30] loss:0.002: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 57.27it/s]\n",
      "[epoch 8] train_loss: 0.050  val_accuracy: 0.987 time:14.409\n",
      "train epoch[9/30] loss:0.012: 100%|████████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 57.22it/s]\n",
      "[epoch 9] train_loss: 0.037  val_accuracy: 0.993 time:14.570\n",
      "train epoch[10/30] loss:0.002: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 55.55it/s]\n",
      "[epoch 10] train_loss: 0.028  val_accuracy: 0.993 time:14.580\n",
      "train epoch[11/30] loss:0.031: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.14it/s]\n",
      "[epoch 11] train_loss: 0.023  val_accuracy: 0.990 time:14.560\n",
      "train epoch[12/30] loss:0.021: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.24it/s]\n",
      "[epoch 12] train_loss: 0.022  val_accuracy: 0.987 time:14.445\n",
      "train epoch[13/30] loss:0.022: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 55.45it/s]\n",
      "[epoch 13] train_loss: 0.017  val_accuracy: 0.990 time:14.398\n",
      "train epoch[14/30] loss:0.001: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 53.87it/s]\n",
      "[epoch 14] train_loss: 0.014  val_accuracy: 0.993 time:14.667\n",
      "train epoch[15/30] loss:0.003: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.81it/s]\n",
      "[epoch 15] train_loss: 0.013  val_accuracy: 0.990 time:14.689\n",
      "train epoch[16/30] loss:0.012: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 57.01it/s]\n",
      "[epoch 16] train_loss: 0.011  val_accuracy: 0.997 time:14.389\n",
      "train epoch[17/30] loss:0.001: 100%|███████████████████████████████████████████████████| 85/85 [00:15<00:00,  5.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 45.47it/s]\n",
      "[epoch 17] train_loss: 0.009  val_accuracy: 1.000 time:17.173\n",
      "train epoch[18/30] loss:0.002: 100%|███████████████████████████████████████████████████| 85/85 [00:15<00:00,  5.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 49.73it/s]\n",
      "[epoch 18] train_loss: 0.008  val_accuracy: 0.997 time:16.764\n",
      "train epoch[19/30] loss:0.001: 100%|███████████████████████████████████████████████████| 85/85 [00:14<00:00,  5.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 52.51it/s]\n",
      "[epoch 19] train_loss: 0.006  val_accuracy: 0.990 time:15.914\n",
      "train epoch[20/30] loss:0.001: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 54.85it/s]\n",
      "[epoch 20] train_loss: 0.006  val_accuracy: 0.990 time:15.266\n",
      "train epoch[21/30] loss:0.000: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 47.11it/s]\n",
      "[epoch 21] train_loss: 0.004  val_accuracy: 0.997 time:15.194\n",
      "train epoch[22/30] loss:0.000: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 50.71it/s]\n",
      "[epoch 22] train_loss: 0.003  val_accuracy: 0.997 time:14.768\n",
      "train epoch[23/30] loss:0.002: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 57.01it/s]\n",
      "[epoch 23] train_loss: 0.003  val_accuracy: 0.997 time:14.324\n",
      "train epoch[24/30] loss:0.007: 100%|███████████████████████████████████████████████████| 85/85 [00:12<00:00,  6.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.86it/s]\n",
      "[epoch 24] train_loss: 0.002  val_accuracy: 0.997 time:14.294\n",
      "train epoch[25/30] loss:0.000: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 57.22it/s]\n",
      "[epoch 25] train_loss: 0.002  val_accuracy: 1.000 time:14.353\n",
      "train epoch[26/30] loss:0.000: 100%|███████████████████████████████████████████████████| 85/85 [00:12<00:00,  6.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 56.84it/s]\n",
      "[epoch 26] train_loss: 0.002  val_accuracy: 0.997 time:14.303\n",
      "train epoch[27/30] loss:0.000: 100%|███████████████████████████████████████████████████| 85/85 [00:13<00:00,  6.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 54.69it/s]\n",
      "[epoch 27] train_loss: 0.001  val_accuracy: 0.993 time:14.575\n",
      "train epoch[28/30] loss:0.000: 100%|███████████████████████████████████████████████████| 85/85 [00:14<00:00,  6.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 50.78it/s]\n",
      "[epoch 28] train_loss: 0.001  val_accuracy: 1.000 time:15.648\n",
      "train epoch[29/30] loss:0.002: 100%|███████████████████████████████████████████████████| 85/85 [00:14<00:00,  5.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 51.12it/s]\n",
      "[epoch 29] train_loss: 0.001  val_accuracy: 1.000 time:16.333\n",
      "train epoch[30/30] loss:0.001: 100%|███████████████████████████████████████████████████| 85/85 [00:15<00:00,  5.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 48.17it/s]\n",
      "[epoch 30] train_loss: 0.001  val_accuracy: 0.997 time:16.861\n",
      "Finished Training\n",
      "[[5.47427916e+04 5.47572801e+04 5.47721600e+04]\n",
      " [5.47866576e+04 5.48011132e+04 5.48154806e+04]\n",
      " [5.48298878e+04 5.48444870e+04 5.48588964e+04]\n",
      " [5.48734660e+04 5.48880463e+04 5.49026066e+04]\n",
      " [5.49170517e+04 5.49314493e+04 5.49461159e+04]\n",
      " [5.49608048e+04 5.49751942e+04 5.49923672e+04]\n",
      " [5.50091317e+04 5.50250456e+04 5.50403119e+04]\n",
      " [5.50555058e+04 5.50702734e+04 5.50845971e+04]\n",
      " [5.50988910e+04 5.51132438e+04 5.51275467e+04]\n",
      " [5.51421219e+04 5.51577694e+04 5.51741020e+04]\n",
      " [5.51909627e+04 0.00000000e+00 9.36454849e-01]\n",
      " [9.46488294e-01 9.69899666e-01 9.69899666e-01]\n",
      " [9.69899666e-01 9.83277592e-01 9.66555184e-01]\n",
      " [9.86622074e-01 9.93311037e-01 9.93311037e-01]\n",
      " [9.89966555e-01 9.86622074e-01 9.89966555e-01]\n",
      " [9.93311037e-01 9.89966555e-01 9.96655518e-01]\n",
      " [1.00000000e+00 9.96655518e-01 9.89966555e-01]\n",
      " [9.89966555e-01 9.96655518e-01 9.96655518e-01]\n",
      " [9.96655518e-01 9.96655518e-01 1.00000000e+00]\n",
      " [9.96655518e-01 9.93311037e-01 1.00000000e+00]\n",
      " [1.00000000e+00 9.96655518e-01 1.00000000e+00]\n",
      " [4.41527901e-01 1.92379954e-01 1.42254657e-01]\n",
      " [1.00947233e-01 8.46750918e-02 6.33422409e-02]\n",
      " [5.23005383e-02 5.02112812e-02 3.72311027e-02]\n",
      " [2.84879806e-02 2.31872395e-02 2.20619193e-02]\n",
      " [1.73735563e-02 1.44363829e-02 1.33646813e-02]\n",
      " [1.09346913e-02 8.63318460e-03 7.57129151e-03]\n",
      " [5.65674136e-03 5.97945475e-03 3.58161798e-03]\n",
      " [3.07332647e-03 2.75884715e-03 1.98044026e-03]\n",
      " [1.70066714e-03 1.61630882e-03 1.18275553e-03]\n",
      " [1.48517162e-03 1.30379478e-03 8.87306915e-04]]\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=test()\n",
    "path_img = './testimages/'\n",
    "ls = os.listdir(path_img)\n",
    "name=[]\n",
    "for i in ls:\n",
    "    name.append(i)\n",
    "import pandas as pd\n",
    "out_dict = {\n",
    "    'image_id':list(name),\n",
    "    'is_male':list(pre)\n",
    "}\n",
    "out = pd.DataFrame(out_dict)\n",
    "out.to_csv('submmit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
