{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms, datasets, utils\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import argparse\n",
    "from typing import Callable, Optional\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import Tensor\n",
    "from utils import read_split_data, train_one_epoch, evaluate\n",
    "from my_dataset import MyDataSet\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from typing import List, Callable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_shuffle(x: Tensor, groups: int) -> Tensor:\n",
    "\n",
    "    batch_size, num_channels, height, width = x.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    # reshape\n",
    "    x = x.view(batch_size, groups, channels_per_group, height, width)\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batch_size, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, input_c: int, output_c: int, stride: int):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "\n",
    "        if stride not in [1, 2]:\n",
    "            raise ValueError(\"illegal stride value.\")\n",
    "        self.stride = stride\n",
    "\n",
    "        assert output_c % 2 == 0\n",
    "        branch_features = output_c // 2\n",
    "        assert (self.stride != 1) or (input_c == branch_features << 1)\n",
    "\n",
    "        if self.stride == 2:\n",
    "            self.branch1 = nn.Sequential(\n",
    "                self.depthwise_conv(input_c, input_c, kernel_s=3, stride=self.stride, padding=1),\n",
    "                nn.BatchNorm2d(input_c),\n",
    "                nn.Conv2d(input_c, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(branch_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.branch1 = nn.Sequential()\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(input_c if self.stride > 1 else branch_features, branch_features, kernel_size=1,\n",
    "                      stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            self.depthwise_conv(branch_features, branch_features, kernel_s=3, stride=self.stride, padding=1),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def depthwise_conv(input_c: int,\n",
    "                       output_c: int,\n",
    "                       kernel_s: int,\n",
    "                       stride: int = 1,\n",
    "                       padding: int = 0,\n",
    "                       bias: bool = False) -> nn.Conv2d:\n",
    "        return nn.Conv2d(in_channels=input_c, out_channels=output_c, kernel_size=kernel_s,\n",
    "                         stride=stride, padding=padding, bias=bias, groups=input_c)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.stride == 1:\n",
    "            x1, x2 = x.chunk(2, dim=1)\n",
    "            out = torch.cat((x1, self.branch2(x2)), dim=1)\n",
    "        else:\n",
    "            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)\n",
    "\n",
    "        out = channel_shuffle(out, 2)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ShuffleNetV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 stages_repeats: List[int],\n",
    "                 stages_out_channels: List[int],\n",
    "                 num_classes: int = 1000,\n",
    "                 inverted_residual: Callable[..., nn.Module] = InvertedResidual):\n",
    "        super(ShuffleNetV2, self).__init__()\n",
    "\n",
    "        if len(stages_repeats) != 3:\n",
    "            raise ValueError(\"expected stages_repeats as list of 3 positive ints\")\n",
    "        if len(stages_out_channels) != 5:\n",
    "            raise ValueError(\"expected stages_out_channels as list of 5 positive ints\")\n",
    "        self._stage_out_channels = stages_out_channels\n",
    "\n",
    "        # input RGB image\n",
    "        input_channels = 3\n",
    "        output_channels = self._stage_out_channels[0]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        input_channels = output_channels\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Static annotations for mypy\n",
    "        self.stage2: nn.Sequential\n",
    "        self.stage3: nn.Sequential\n",
    "        self.stage4: nn.Sequential\n",
    "\n",
    "        stage_names = [\"stage{}\".format(i) for i in [2, 3, 4]]\n",
    "        for name, repeats, output_channels in zip(stage_names, stages_repeats,\n",
    "                                                  self._stage_out_channels[1:]):\n",
    "            seq = [inverted_residual(input_channels, output_channels, 2)]\n",
    "            for i in range(repeats - 1):\n",
    "                seq.append(inverted_residual(output_channels, output_channels, 1))\n",
    "            setattr(self, name, nn.Sequential(*seq))\n",
    "            input_channels = output_channels\n",
    "\n",
    "        output_channels = self._stage_out_channels[-1]\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(output_channels, num_classes)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.mean([2, 3]) \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def shufflenet_v2_x1_0(num_classes=1000):\n",
    "    model = ShuffleNetV2(stages_repeats=[4, 8, 4],\n",
    "                         stages_out_channels=[24, 116, 232, 464, 1024],\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(args)\n",
    "    print('Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/')\n",
    "    tb_writer = SummaryWriter()\n",
    "    if os.path.exists(\"./weights\") is False:\n",
    "        os.makedirs(\"./weights\")\n",
    "\n",
    "    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "        \"val\": transforms.Compose([transforms.Resize((224, 224)),  \n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\n",
    "\n",
    "    # 实例化训练数据集\n",
    "    train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                              transform=data_transform[\"train\"])\n",
    "\n",
    "    # 实例化验证数据集\n",
    "    val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                            transform=data_transform[\"val\"])\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    nw=0\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=nw,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=nw,\n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "    # 如果存在预训练权重则载入\n",
    "    model = shufflenet_v2_x1_0(num_classes=args.num_classes).to(device)\n",
    "    if args.weights != \"\":\n",
    "        if os.path.exists(args.weights):\n",
    "            weights_dict = torch.load(args.weights, map_location=device)\n",
    "            load_weights_dict = {k: v for k, v in weights_dict.items()\n",
    "                                 if model.state_dict()[k].numel() == v.numel()}\n",
    "            print(model.load_state_dict(load_weights_dict, strict=False))\n",
    "        else:\n",
    "            raise FileNotFoundError(\"not found weights file: {}\".format(args.weights))\n",
    "\n",
    "    # 是否冻结权重\n",
    "    if args.freeze_layers:\n",
    "        for name, para in model.named_parameters():\n",
    "            # 除最后的全连接层外，其他权重全部冻结\n",
    "            if \"fc\" not in name:\n",
    "                para.requires_grad_(False)\n",
    "\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.SGD(pg, lr=args.lr, momentum=0.9, weight_decay=4E-5)\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / args.epochs)) / 2) * (1 - args.lrf) + args.lrf  # cosine\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "    timlist=[]\n",
    "    t_loss=[]\n",
    "    val_a=[]\n",
    "    nowtim=time.perf_counter()\n",
    "    timlist.append(nowtim)\n",
    "    val_a.append(0)\n",
    "    t_loss.append(1)\n",
    "    for epoch in range(args.epochs):\n",
    "        # train\n",
    "        mean_loss = train_one_epoch(model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    data_loader=train_loader,\n",
    "                                    device=device,\n",
    "                                    epoch=epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # validate\n",
    "        acc = evaluate(model=model,\n",
    "                       data_loader=val_loader,\n",
    "                       device=device)\n",
    "\n",
    "        print(\"[epoch {}] accuracy: {}\".format(epoch, round(acc, 3)))\n",
    "        tags = [\"loss\", \"accuracy\", \"learning_rate\"]\n",
    "        tb_writer.add_scalar(tags[0], mean_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[1], acc, epoch)\n",
    "        tb_writer.add_scalar(tags[2], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "        tim=time.perf_counter()\n",
    "        nowtim=tim\n",
    "        timlist.append(nowtim)\n",
    "        val_a.append(acc)\n",
    "        t_loss.append(mean_loss)\n",
    "        torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    data_transform = transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    # load image\n",
    "    path_img = './testimages/'\n",
    "    ls = os.listdir(path_img)\n",
    "    pre=[]\n",
    "    for i in ls:\n",
    "        img = Image.open(f\"./testimages/{i}\")\n",
    "    # [N, C, H, W]\n",
    "        img = data_transform(img)\n",
    "        # expand batch dimension\n",
    "        img = torch.unsqueeze(img, dim=0)\n",
    "        #print(img)\n",
    "        # read class_indict\n",
    "        json_path = './class_indices.json'\n",
    "        assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            class_indict = json.load(f)\n",
    "\n",
    "        # create model\n",
    "        model = shufflenet_v2_x1_0(num_classes=2).to(device)\n",
    "        # load model weights\n",
    "        model_weight_path = \"./weights/model-29.pth\"\n",
    "        model.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # predict class\n",
    "            output = torch.squeeze(model(img.to(device))).cpu()\n",
    "            predict = torch.softmax(output, dim=0)\n",
    "            predict_cla = torch.argmax(predict).numpy()\n",
    "\n",
    "        print_res = \"class: {}   prob: {:.3}\".format(class_indict[str(predict_cla)],\n",
    "                                                     predict[predict_cla].numpy())\n",
    "        if class_indict[str(predict_cla)]=='male':\n",
    "            pre.append(1)\n",
    "        else:\n",
    "            pre.append(-1)\n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, data_path='../../data_set/flower_data/flower_photos', device='cuda:0', epochs=30, freeze_layers=False, lr=0.01, lrf=0.1, num_classes=2, weights='./shufflenetv2_x1-5666bf0f80.pth')\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "3000 images were found in the dataset.\n",
      "2401 images for training.\n",
      "599 images for validation.\n",
      "Using 0 dataloader workers every process\n",
      "_IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=[])\n",
      "[epoch 0] mean loss 0.69:   2%|█                                                       | 3/151 [00:02<02:21,  1.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fd09bfa21897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-30f6a4214d4b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         mean_loss = train_one_epoch(model=model,\n\u001b[0m\u001b[0;32m     82\u001b[0m                                     \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                                     \u001b[0mdata_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\mymodel\\pytorch_classification\\Test7_shufflenet\\utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             F.sgd(params_with_grad,\n\u001b[0m\u001b[0;32m    137\u001b[0m                   \u001b[0md_p_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                   \u001b[0mmomentum_buffer_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--num_classes', type=int, default=2)\n",
    "parser.add_argument('--epochs', type=int, default=30)\n",
    "parser.add_argument('--batch-size', type=int, default=32)\n",
    "parser.add_argument('--lr', type=float, default=0.0002)\n",
    "parser.add_argument('--lrf', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--data-path', type=str,default=\"../../data_set/face_data/face_photos\")\n",
    "\n",
    "\n",
    "parser.add_argument('--weights', type=str, default='./shufflenetv2_x1-5666bf0f80.pth',help='initial weights path')\n",
    "parser.add_argument('--freeze-layers', type=bool, default=False)\n",
    "parser.add_argument('--device', default='cuda:0', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "train(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=test()\n",
    "path_img = './testimages/'\n",
    "ls = os.listdir(path_img)\n",
    "name=[]\n",
    "for i in ls:\n",
    "    name.append(i)\n",
    "import pandas as pd\n",
    "out_dict = {\n",
    "    'image_id':list(name),\n",
    "    'is_male':list(pre)\n",
    "}\n",
    "out = pd.DataFrame(out_dict)\n",
    "out.to_csv('shufflenet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
